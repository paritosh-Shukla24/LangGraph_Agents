{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langgraph-prerequist'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-communityNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.3 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.3.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.3.10)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.1.134)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (1.26.0)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ashutosh\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain-community) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.4/2.4 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.4 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.9/2.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 3.1 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Using cached marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.2 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000242575BEF00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-community/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000024255EA3680>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-community/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000242575BC7D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-community/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000242575BFA10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-community/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000242575BFAD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/langchain-community/\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")'''\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday, dear [Your Name],\\nHappy birthday to you! ðŸŽ‚ðŸŽ‰ \\n\\n\\nLet me know if you'd like me to sing it in a different tone or with some extra musical flair! ðŸŽ¶  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 14, 'total_tokens': 75, 'completion_time': 0.110909091, 'prompt_time': 8.378e-05, 'queue_time': 0.014205579, 'total_time': 0.110992871}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b1e86b0b-d53a-430f-bf11-fad43b00ec51-0', usage_metadata={'input_tokens': 14, 'output_tokens': 61, 'total_tokens': 75})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")'''\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "llm2=ChatGroq(model_name=\"Gemma2-9b-It\")\n",
    "llm2.invoke(\"tell me happy birthday song\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! ðŸ‘‹ How can I help you today? ðŸ˜Š  \n",
      "\n",
      "A black hole is a region of spacetime where gravity is so strong that nothing, not even light, can escape. \n",
      "\n",
      "Here's a breakdown:\n",
      "\n",
      "* **Extreme Gravity:** Black holes form when massive stars collapse at the end of their life cycle. This collapse concentrates an immense amount of mass into an incredibly small space.\n",
      "* **Event Horizon:** The boundary around a black hole beyond which escape is impossible is called the event horizon.  \n",
      "* **Singularity:** At the center of a black hole is thought to be a singularity, a point of infinite density where the laws of physics as we know them break down.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* **Invisible:** We can't see black holes directly because they don't emit light.\n",
      "* **Detected indirectly:** We detect them by observing their gravitational effects on nearby objects, such as stars or gas.\n",
      "* **Types:** Black holes come in different sizes:\n",
      "    * **Stellar-mass black holes:**  Form from the collapse of individual stars.\n",
      "    * **Supermassive black holes:**  Millions or billions of times more massive than our sun, found at the centers of most galaxies, including our own Milky Way.\n",
      "    * **Intermediate-mass black holes:**  Somewhere in between stellar-mass and supermassive black holes.\n",
      "\n",
      "**Fun Fact:**\n",
      "\n",
      "The name \"black hole\" was coined by physicist John Wheeler in 1967.\n",
      "\n",
      "\n",
      "Let me know if you'd like to know more about a specific aspect of black holes!\n",
      "\n",
      "goodbye take care yourself\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question=input(\"type your question. if you want to quit the chat write quit\")\n",
    "    if question !=\"quit\":\n",
    "        print(llm.invoke(question).content)\n",
    "    else:\n",
    "        print(\"goodbye take care yourself\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory=RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Paritosh Shukla! \\n\\nIt's nice to meet you.  What can I do for you today? ðŸ˜Š \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_with_memory.invoke((\"Hi! I'm Paritosh Shukla\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Paritosh Shukla\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Parm Paritosh Shukla! Nice to meet you.  \\n\\nIt's great to have you here. Is there anything I can help you with today? ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 18, 'total_tokens': 58, 'completion_time': 0.072727273, 'prompt_time': 8.224e-05, 'queue_time': 0.014257678, 'total_time': 0.072809513}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-db59d279-4cf4-4e85-8f0c-d394241f9f4b-0', usage_metadata={'input_tokens': 18, 'output_tokens': 40, 'total_tokens': 58}), HumanMessage(content=\"Hi! I'm Paritosh Shukla\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Paritosh Shukla! \\n\\nIt's nice to meet you.  What can I do for you today? ðŸ˜Š \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 74, 'total_tokens': 104, 'completion_time': 0.054545455, 'prompt_time': 0.002104031, 'queue_time': 0.012239962, 'total_time': 0.056649486}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-86160c54-ef2f-45eb-bf87-1c965bf42b34-0', usage_metadata={'input_tokens': 74, 'output_tokens': 30, 'total_tokens': 104}), HumanMessage(content='tell me what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Paritosh Shukla. ðŸ˜Š  \\n\\nI remember!  Is there anything else I can help you with?  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 119, 'total_tokens': 148, 'completion_time': 0.052727273, 'prompt_time': 0.003646045, 'queue_time': 0.011840998, 'total_time': 0.056373318}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb12823f-2713-4bb5-af7d-606a27fd6a55-0', usage_metadata={'input_tokens': 119, 'output_tokens': 29, 'total_tokens': 148})])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Paritosh Shukla. ðŸ˜Š  \\n\\nI remember!  Is there anything else I can help you with?  \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"tell me what is my name?\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('C:\\\\Users\\\\ashutosh\\\\OneDrive\\\\Desktop\\\\Gen AI\\\\LangGraph\\\\data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "'''from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "'''\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = FAISS.from_documents(new_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (1.26.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ashutosh\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.9.0-cp312-cp312-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB 325.1 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.0/14.9 MB 325.1 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.0/14.9 MB 325.1 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.0/14.9 MB 325.1 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.0/14.9 MB 325.1 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.1/14.9 MB 379.3 kB/s eta 0:00:39\n",
      "   - -------------------------------------- 0.5/14.9 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.0/14.9 MB 2.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.4/14.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.9/14.9 MB 3.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.4/14.9 MB 4.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.9/14.9 MB 5.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.4/14.9 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.9/14.9 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.4/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.7/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.8/14.9 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.1/14.9 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.6/14.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.0/14.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.5/14.9 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.0/14.9 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.6/14.9 MB 7.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.0/14.9 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.2/14.9 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.5/14.9 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.9/14.9 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.3/14.9 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.6/14.9 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.8/14.9 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.2/14.9 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.4/14.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.6/14.9 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 8.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.9/14.9 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.0/14.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.2/14.9 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.9 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.4/14.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.6/14.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.7/14.9 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.8/14.9 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.0/14.9 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.1/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.2/14.9 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.5/14.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.0/14.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.1/14.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/14.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.0/14.9 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "and ellaborate the answer in short 2 3 line\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context states: \"Sandy soil is well-draining, making it ideal\".  \n",
      "\n",
      "While it doesn't list specific crops, well-draining soil is generally good for crops that tolerate drought conditions and don't like \"wet feet\". \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question =\" What are the best crops to grow in sandy soil?\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Start with Tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (pyproject.toml): started\n",
      "  Building wheel for wikipedia (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11705 sha256=8f08734017443229b3cf55f272eeb8f6ff3f176368ad65de7d8d5230b3d49e98\n",
      "  Stored in directory: c:\\users\\ashutosh\\appdata\\local\\pip\\cache\\wheels\\63\\47\\7c\\a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashutosh\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3526: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiInputs(BaseModel):\n",
    "    query: str = Field(description=\"query to look up in Wikipedia, should be 3 or less words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_subclass_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tool\u001b[38;5;241m=\u001b[39m\u001b[43mWikipediaQueryRun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki-tool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlook up things in wikipedia\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWikiInputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ashutosh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\tools\\base.py:432\u001b[0m, in \u001b[0;36mBaseTool.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs_schema must be a subclass of pydantic BaseModel. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs_schema\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m     )\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 432\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ashutosh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\load\\serializable.py:111\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ashutosh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for WikipediaQueryRun\nargs_schema\n  Input should be a subclass of BaseModel [type=is_subclass_of, input_value=<class '__main__.WikiInputs'>, input_type=ModelMetaclass]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_subclass_of"
     ]
    }
   ],
   "source": [
    "tool=WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"look up things in wikipedia\",\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "print(tool.run(\"langchain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# youtube search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_search\n",
      "  Using cached youtube_search-2.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from youtube_search) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->youtube_search) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->youtube_search) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->youtube_search) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashutosh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->youtube_search) (2023.7.22)\n",
      "Using cached youtube_search-2.1.2-py3-none-any.whl (3.4 kB)\n",
      "Installing collected packages: youtube_search\n",
      "Successfully installed youtube_search-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=aQpJ7OgXVn8&pp=ygURSW5kaWFzIEdvdCBMYXRlbmQ%3D', 'https://www.youtube.com/watch?v=Vsx9a7-IXX4&pp=ygURSW5kaWFzIEdvdCBMYXRlbmQ%3D']\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"Indias Got Latend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tavily_api_key="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.npr.org/2023/09/03/1197497458/the-latest-on-the-burning-man-flooding',\n",
       "  'content': \"There are also reports that at least one person has died at the counterculture festival about a hundred miles north of Reno, Nev. Earlier this afternoon, I caught up with NPR's Claudia Peschiutta, who's at her first burn, and she told me it's muddy where she is, but that she and her camp family have been making the best of things.\\n National\\nThe latest on the Burning Man flooding\\nClaudia Peschiutta\\nAuthorities are investigating a death at the Burning Man festival in the Nevada desert after tens of thousands of people are stuck in camps because of rain.\\n SCOTT DETROW, HOST:\\nKnee-deep mud, warnings to conserve food and water, orders to shelter in place - this is all at Burning Man 2023 after torrential rains turned the Black Rock Desert into miles and miles of mud. I mean, mostly what I've seen from my personal experience is just any sort of need that you have, somebody, whether friend or neighbor or stranger, will jump in to help you out in some way. And I should mention that desert Wi-Fi is doing the best as it can as we talk to you, dropping in and out.\"},\n",
       " {'url': 'https://www.nbcnews.com/news/us-news/live-blog/live-updates-burning-man-flooding-keeps-thousands-stranded-nevada-site-rcna103193',\n",
       "  'content': \"Profile\\nSections\\ntv\\nFeatured\\nMore From NBC\\nFollow NBC News\\nnews Alerts\\nThere are no new alerts at this time\\nBurning Man flooding keeps thousands stranded at Nevada site as authorities investigate 1 death\\nBurning Man attendees struggling to get home\\n70,000+ stuck at Burning Man: When will they be able to get out?\\n Thousands still stranded at Burning Man after torrential rain\\nBurning Man revelers unfazed by deluge and deep mud\\nReuters\\nThousands of Burning Man attendees partied hard on Sunday despite downpours that turned the Nevada desert where the annual arts and music festival takes place into a sea of sticky mud and led officials to order the multitudes to shelter in place.\\n Neal Katyal warns hiking in the mud\\ncan be 'worse than walking on ice'\\nDoha Madani\\nNeal Katyal, the former acting U.S. solicitor general, is among the Burning Man attendees who decided to take the risk and hike out of the festival grounds.\\n Videos posted to his Instagram story show Diplo walking through mud before, he says, he hitchhiked to Gerlach and Reno to make a flight to Washington, D.C.\\nâ€œI just got done DJâ€™ing for three hours, after walking f---ing for four hours out of the desert and taking a flight, mud still on my face,â€ he said in a video posted to his Instagram story last night.\\n Burning Man memes are swamping social media\\nAngela Yang\\nAs heavy rain turns Burning Man 2023 into a muddy mess, a deluge of unsympathetic jokes has swamped the internet outside Black Rock City, the temporary location built annually for the nine-day festival in the remote desert of Nevada.\\n\"},\n",
       " {'url': 'https://www.cnn.com/2023/09/05/us/burning-man-storms-shelter-exodus-tuesday/index.html',\n",
       "  'content': \"CNN values your feedback\\nBurning Man attendees make a mass exodus after a dramatic weekend that left thousands stuck in the Nevada desert\\nThousands of Burning Man attendees finally made their mass exodus after intense rain over the weekend flooded camp sites and filled them with thick, ankle-deep mud â€“ stranding more than 70,000 free-spirited revelers as they waited for the Nevada desert city to dry out.\\n Burning Man organizers lift driving ban after heavy rains left the event smothered in mud and trapped thousands\\nThe area was still muddy and parts were still difficult to navigate, organizers warned, and the wait time to leave the city Monday night was about seven hours. Diplo hitchhiked ride out of rain-drenched Burning Man after walking miles 'through the mud' and actually made it to his DC concert\\nâ€œQuite a wet start to September for much of eastern CA-western NV,â€ the National Weather Service in Reno wrote on X. â€ â€œAs soon as the tents started getting water-logged or unlivable, people in RVs started taking in some of the tenters, so everybody was warm,â€ Kaz Qamruddin, who attended the event, told CNNâ€™s Brianna Keilar Monday.\\n From wood blocks to 'poop buckets,' how Burning Man organizers told festivalgoers to prepare for heavy rain\\nAmong the early departures was music DJ Diplo, who told CNN he walked several miles in the muddy desert Saturday morning along with other celebrities, including Chris Rock, Cindy Crawford, Kaia Gerber and Austin Butler.\"},\n",
       " {'url': 'https://abcnews.go.com/US/burning-man-flooding-happened-stranded-festivalgoers/story?id=102908331',\n",
       "  'content': '\"\\nTop Stories\\nMacy\\'s Thanksgiving Day Parade temporarily halted by pro-Palestinian protesters\\nGuns N\\' Roses singer Axl Rose accused of alleged 1989 sexual assault by former model\\nFBI: Rainbow Bridge crash, explosion not connected to terrorism\\nToxic chemical spill from Kentucky train derailment forces residents to flee homes\\nHezbollah fires rockets at north Israel after an airstrike kills 5 of the group\\'s senior fighters\\nABC News Live\\n24/7 coverage of breaking news and live events ABC News\\nVideo\\nLive\\nShows\\nElection 2024\\n538\\nStream on\\nBurning Man flooding: What happened to stranded festivalgoers?\\n In response to the unusual weather, event organizers shut down traffic in or out of what is called Black Rock City -- where the festival is held in the desert -- including the local airport.\\n MORE: These US regions will experience scorching temperatures for the remainder of Labor Day weekend\\nOn Sunday, mobile cell trailers to boost cell service and charging stations were placed around the festival grounds amid the recovery efforts, according to organizers.\\n This is typically the driest time of the year for the desert, and it does not take much rain to make the desert floor a mud bath.\\n'},\n",
       " {'url': 'https://www.cnn.com/us/live-news/nevada-desert-burning-man-weather-rain-09-03-23/index.html',\n",
       "  'content': 'The festivalâ€™s 2023 theme is â€œAnimalia,â€ which the Burning Man website explains, â€œwill celebrate the animal world and our place in it â€” animals real and imagined, mythic and remembered â€” and explore the curious mental constructs that allow us to believe that imagined animals are real, real animals are imagined, and that somehow, despite all evidence to the contrary, mankind is somehow not part of the animal kingdom.â€\\n Thousands stranded at Burning Man festival after heavy rains\\nBy Maureen Chowdhury, Steve Almasy and Matt Meyer, CNN\\nWhat we\\'re covering\\nPresident Biden has been briefed on the situation at Burning Man festival\\nFrom CNN\\'s Betsy Klein\\nPresident Joe Biden was briefed Sunday on the situation at the Burning Man festival in Black Rock Desert, Nevada, according to a White House official.\\n View Katyal\\'s post below:\\nSome of the 70,000 people stranded at Burning Man are walking out of the site, sheriff\\'s office says\\nFrom CNN\\'s Melissa Alonso\\nThere are currently \"a little over 70,000\" people stranded at the Burning Man festival in Nevada due to the mud and flooding, Pershing County Sheriffâ€™s Sgt. Burning Man organizers working to provide cell service and medical resources as attendees shelter in place\\nFrom CNN\\'s Nouran Salahieh\\xa0and\\xa0Emma Tucker\\nBurning Man organizers say they are placing mobile cell trailers around the battered festival grounds, configuring their Wi-Fi system for public access, and sending buses to nearby Gerlach, Nevada, to pick up people who might have walked out of the desert and ferry them to Reno.\\n Festivalgoers are managing to have a good time despite being stuck in the mud, attendee says\\nDawne Looney, a Burning Man festival attendee, says people are making the best of the situation despite the heavy rain and mud stranding an estimated 70,000 of them in the desert.\\n'}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({\"query\": \"What happened in the latest burning man floods\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor,create_openai_functions_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an assistant.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'who was the mahatma gandhi', 'output': ''}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.invoke({\"input\": \"who was the mahatma gandhi\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase that one more agent also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our custom agent and custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashutosh\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3526: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "Look up things online.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search-tool\n",
      "Look up things online.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\LangGraph-End-to-End-Course\\venv\\lib\\site-packages\\pydantic\\json_schema.py:2191: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='should be a search query' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)\n",
    "print(search.return_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here is my custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'eudca'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3m5\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188'), observation=5)],\n",
       "  'messages': [FunctionMessage(content='5', additional_kwargs={}, response_metadata={}, name='get_word_length')]},\n",
       " {'output': '5',\n",
       "  'messages': [AIMessage(content='5', additional_kwargs={}, response_metadata={})]}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"How many letters in the word eudca\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188')],\n",
    "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])]},\n",
    " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_4188', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-6cc153ac-50f7-468e-871a-bb81fd15b1f7', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_4188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 966, 'output_tokens': 86, 'total_tokens': 1052}, tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_4188', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_4188'), observation=5)],\n",
    "  'messages': [FunctionMessage(content='5', additional_kwargs={}, response_metadata={}, name='get_word_length')]},\n",
    " {'output': '5',\n",
    "  'messages': [AIMessage(content='5', additional_kwargs={}, response_metadata={})]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s how to solve this:\\n\\n* **Focus on the phrase:**  The question asks about the letters in the phrase \"letters in the word educa\".\\n* **Count carefully:** Count each letter in that phrase.\\n\\nLet me know if you\\'d like me to do the counting for you! \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 16, 'total_tokens': 83, 'completion_time': 0.121818182, 'prompt_time': 0.00024042, 'queue_time': 0.042495864, 'total_time': 0.122058602}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ed352c53-84e7-48d6-9576-0acd99befd1f-0', usage_metadata={'input_tokens': 16, 'output_tokens': 67, 'total_tokens': 83})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How many letters in the word educa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m5\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYes. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'is that a real word?',\n",
       " 'chat_history': [HumanMessage(content='how many letters in the word educa?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='5', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Yes. \\n'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
